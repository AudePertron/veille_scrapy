{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veille Webscraping\n",
    "\n",
    "Patricia <br>\n",
    "Guillaume<br>\n",
    "Aude<br>\n",
    "Eva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source :\n",
    "https://docs.scrapy.org/en/latest/intro/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy est un framework open-source permettant la création de robots d'indexation. Développé en Python, il dispose d'une forte communauté, offrant de nombreux modules supplémentaires. La première version stable a été publiée en septembre 2009.\n",
    "___\n",
    "Scrapy est un outil créer spécifique pour effectuer des requêtes, scraper et sauvegarder des données sur le web il se suffit à lui même pour construire un projet de webscraping robuste \n",
    "tandis que BeautifulSoup est un package utilitaire qui nous sera seulement utile pour accéder aux éléments d’une page web, il sera souvent nécessaire d’importer des librairies supplémentaires tels que requests ou urllib2 et d’autres pour avoir l’étendu des fonctionnalités de Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#en ligne de commande, dans le dossier où l'on veut déployer le scraper\n",
    "pip install scrapy\n",
    "scrapy startproject tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[tutorial]' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "![tutorial](images/scrapy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'http://quotes.toscrape.com/page/1/',\n",
    "            'http://quotes.toscrape.com/page/2/',\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = f'quotes-{page}.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log(f'Saved file {filename}')\n",
    "        \n",
    "#sauvegarder cette fonction en tant que quotes_spider.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#dans le terminal\n",
    "$scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela va créer des pages html avec le contenu des pages d'origine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution deux\n",
    "Intégralement dans le terminal"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scrapy shell http://quotes.toscrape.com/page/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toujours dans le terminal !\n",
    "for quote in response.css(\"div.quote\"):\n",
    "  text = quote.css(\"span.text::text\").get()\n",
    "  author = quote.css(\"small.author::text\").get()\n",
    "  tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "  print(dict(text=text, author=author, tags=tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
